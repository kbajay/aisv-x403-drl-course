{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-27 11:43:38.529855: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-03-27 11:43:38.529906: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import, division, print_function\n",
    "\n",
    "import IPython\n",
    "import numpy as np\n",
    "import base64\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from tf_agents.agents.dqn import dqn_agent\n",
    "from tf_agents.environments import suite_gym\n",
    "from tf_agents.environments import tf_py_environment\n",
    "from tf_agents.networks import q_network\n",
    "from tf_agents.policies import random_tf_policy\n",
    "from tf_agents.replay_buffers import tf_uniform_replay_buffer\n",
    "from tf_agents.trajectories import trajectory\n",
    "from tf_agents.utils import common"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_iterations = 5000 # @param {type:\"integer\"}\n",
    "\n",
    "initial_collect_steps = 100  # @param {type:\"integer\"}\n",
    "collect_steps_per_iteration =   1# @param {type:\"integer\"}\n",
    "replay_buffer_max_length = 1000  # @param {type:\"integer\"}\n",
    "\n",
    "batch_size = 64  # @param {type:\"integer\"}\n",
    "learning_rate = 1e-3  # @param {type:\"number\"}\n",
    "log_interval = 200  # @param {type:\"integer\"}\n",
    "\n",
    "num_eval_episodes = 10  # @param {type:\"integer\"}\n",
    "eval_interval = 1000  # @param {type:\"integer\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TimeStep(\n",
       "{'discount': array(1., dtype=float32),\n",
       " 'observation': array(162),\n",
       " 'reward': array(0., dtype=float32),\n",
       " 'step_type': array(0, dtype=int32)})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env_name = 'Taxi-v3'\n",
    "env = suite_gym.load(env_name)\n",
    "env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#env.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observation Spec:\n",
      "BoundedArraySpec(shape=(), dtype=dtype('int64'), name='observation', minimum=0, maximum=499)\n"
     ]
    }
   ],
   "source": [
    "print('Observation Spec:')\n",
    "print(env.time_step_spec().observation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reward Spec:\n",
      "ArraySpec(shape=(), dtype=dtype('float32'), name='reward')\n"
     ]
    }
   ],
   "source": [
    "print('Reward Spec:')\n",
    "print(env.time_step_spec().reward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action Spec:\n",
      "BoundedArraySpec(shape=(), dtype=dtype('int64'), name='action', minimum=0, maximum=5)\n"
     ]
    }
   ],
   "source": [
    "print('Action Spec:')\n",
    "print(env.action_spec())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time step:\n",
      "TimeStep(\n",
      "{'discount': array(1., dtype=float32),\n",
      " 'observation': array(169),\n",
      " 'reward': array(0., dtype=float32),\n",
      " 'step_type': array(0, dtype=int32)})\n",
      "Next time step:\n",
      "TimeStep(\n",
      "{'discount': array(1., dtype=float32),\n",
      " 'observation': array(69),\n",
      " 'reward': array(-1., dtype=float32),\n",
      " 'step_type': array(1, dtype=int32)})\n"
     ]
    }
   ],
   "source": [
    "time_step = env.reset()\n",
    "print('Time step:')\n",
    "print(time_step)\n",
    "\n",
    "action = np.array(1, dtype=np.int32)\n",
    "\n",
    "next_time_step = env.step(action)\n",
    "print('Next time step:')\n",
    "print(next_time_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_py_env = suite_gym.load(env_name)\n",
    "eval_py_env = suite_gym.load(env_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_env = tf_py_environment.TFPyEnvironment(train_py_env)\n",
    "eval_env = tf_py_environment.TFPyEnvironment(eval_py_env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fc_layer_params = (10, 10, 50, 50, )\n",
    "fc_layer_params = (100, )\n",
    "q_net = q_network.QNetwork(\n",
    "    train_env.observation_spec(),\n",
    "    train_env.action_spec(),\n",
    "    fc_layer_params=fc_layer_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-27 11:43:55.610390: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:922] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-03-27 11:43:55.610591: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-03-27 11:43:55.610638: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory\n",
      "2022-03-27 11:43:55.610714: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory\n",
      "2022-03-27 11:43:55.610788: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcufft.so.10'; dlerror: libcufft.so.10: cannot open shared object file: No such file or directory\n",
      "2022-03-27 11:43:55.610828: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcurand.so.10'; dlerror: libcurand.so.10: cannot open shared object file: No such file or directory\n",
      "2022-03-27 11:43:55.610863: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory\n",
      "2022-03-27 11:43:55.610895: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory\n",
      "2022-03-27 11:43:55.610961: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2022-03-27 11:43:55.610971: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1850] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2022-03-27 11:43:55.611550: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "\n",
    "train_step_counter = tf.Variable(0)\n",
    "\n",
    "agent = dqn_agent.DqnAgent(\n",
    "    train_env.time_step_spec(),\n",
    "    train_env.action_spec(),\n",
    "    q_network=q_net,\n",
    "    optimizer=optimizer,\n",
    "    td_errors_loss_fn=common.element_wise_squared_loss,\n",
    "    train_step_counter=train_step_counter)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_policy = agent.policy\n",
    "collect_policy = agent.collect_policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_policy = random_tf_policy.RandomTFPolicy(train_env.time_step_spec(),\n",
    "                                                train_env.action_spec())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_avg_return(environment, policy, num_episodes=10):\n",
    "\n",
    "  total_return = 0.0\n",
    "  for _ in range(num_episodes):\n",
    "\n",
    "    time_step = environment.reset()\n",
    "    episode_return = 0.0\n",
    "\n",
    "    while not time_step.is_last():\n",
    "      action_step = policy.action(time_step)\n",
    "      time_step = environment.step(action_step.action)\n",
    "      episode_return += time_step.reward\n",
    "    total_return += episode_return\n",
    "\n",
    "  avg_return = total_return / num_episodes\n",
    "  return avg_return.numpy()[0]\n",
    "\n",
    "\n",
    "# See also the metrics module for standard implementations of different metrics.\n",
    "# https://github.com/tensorflow/agents/tree/master/tf_agents/metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-774.1"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_avg_return(eval_env, random_policy, num_eval_episodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "replay_buffer = tf_uniform_replay_buffer.TFUniformReplayBuffer(\n",
    "    data_spec=agent.collect_data_spec,\n",
    "    batch_size=train_env.batch_size,\n",
    "    max_length=replay_buffer_max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trajectory(\n",
      "{'action': BoundedTensorSpec(shape=(), dtype=tf.int64, name='action', minimum=array(0), maximum=array(5)),\n",
      " 'discount': BoundedTensorSpec(shape=(), dtype=tf.float32, name='discount', minimum=array(0., dtype=float32), maximum=array(1., dtype=float32)),\n",
      " 'next_step_type': TensorSpec(shape=(), dtype=tf.int32, name='step_type'),\n",
      " 'observation': BoundedTensorSpec(shape=(), dtype=tf.int64, name='observation', minimum=array(0), maximum=array(499)),\n",
      " 'policy_info': (),\n",
      " 'reward': TensorSpec(shape=(), dtype=tf.float32, name='reward'),\n",
      " 'step_type': TensorSpec(shape=(), dtype=tf.int32, name='step_type')})\n",
      "('step_type', 'observation', 'action', 'policy_info', 'next_step_type', 'reward', 'discount')\n"
     ]
    }
   ],
   "source": [
    "print(agent.collect_data_spec)\n",
    "print(agent.collect_data_spec._fields)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_step(environment, policy, buffer):\n",
    "  time_step = environment.current_time_step()\n",
    "  action_step = policy.action(time_step)\n",
    "  # Do not use the below. It use tensor objects which cause error\n",
    "  # next_time_step = environment.step(action_step.action)\n",
    "  # For step argument, we put numpy object as action integer like below\n",
    "  next_time_step = environment.step(action_step.action.numpy()[0])\n",
    "  traj = trajectory.from_transition(time_step, action_step, next_time_step)\n",
    "\n",
    "  # Add trajectory to the replay buffer\n",
    "  buffer.add_batch(traj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_data(env, policy, buffer, steps):\n",
    "  for _ in range(steps):\n",
    "    collect_step(env, policy, buffer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "collect_data(train_env, random_policy, replay_buffer, steps=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf_agents.replay_buffers.tf_uniform_replay_buffer.TFUniformReplayBuffer at 0x7fb42c05c6d0>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "replay_buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ajay/.local/lib/python3.8/site-packages/tensorflow/python/autograph/impl/api.py:377: ReplayBuffer.get_next (from tf_agents.replay_buffers.replay_buffer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `as_dataset(..., single_deterministic_pass=False) instead.\n"
     ]
    }
   ],
   "source": [
    "dataset = replay_buffer.as_dataset(\n",
    "    num_parallel_calls=3,\n",
    "    sample_batch_size=batch_size,\n",
    "    num_steps=2).prefetch(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<PrefetchDataset element_spec=(Trajectory(\n",
       "{'action': TensorSpec(shape=(64, 2), dtype=tf.int64, name=None),\n",
       " 'discount': TensorSpec(shape=(64, 2), dtype=tf.float32, name=None),\n",
       " 'next_step_type': TensorSpec(shape=(64, 2), dtype=tf.int32, name=None),\n",
       " 'observation': TensorSpec(shape=(64, 2), dtype=tf.int64, name=None),\n",
       " 'policy_info': (),\n",
       " 'reward': TensorSpec(shape=(64, 2), dtype=tf.float32, name=None),\n",
       " 'step_type': TensorSpec(shape=(64, 2), dtype=tf.int32, name=None)}), BufferInfo(ids=TensorSpec(shape=(64, 2), dtype=tf.int64, name=None), probabilities=TensorSpec(shape=(64,), dtype=tf.float32, name=None)))>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tensorflow.python.data.ops.iterator_ops.OwnedIterator object at 0x7fb4245c5a00>\n"
     ]
    }
   ],
   "source": [
    "iterator = iter(dataset)\n",
    "print(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Trajectory(\n",
       " {'action': <tf.Tensor: shape=(64, 2), dtype=int64, numpy=\n",
       " array([[1, 3],\n",
       "        [3, 5],\n",
       "        [1, 3],\n",
       "        [3, 3],\n",
       "        [2, 0],\n",
       "        [4, 4],\n",
       "        [3, 3],\n",
       "        [4, 0],\n",
       "        [0, 1],\n",
       "        [3, 3],\n",
       "        [3, 1],\n",
       "        [3, 3],\n",
       "        [2, 0],\n",
       "        [5, 5],\n",
       "        [3, 2],\n",
       "        [2, 3],\n",
       "        [4, 2],\n",
       "        [2, 3],\n",
       "        [5, 2],\n",
       "        [3, 3],\n",
       "        [0, 2],\n",
       "        [3, 2],\n",
       "        [4, 3],\n",
       "        [4, 0],\n",
       "        [4, 3],\n",
       "        [0, 2],\n",
       "        [5, 1],\n",
       "        [3, 2],\n",
       "        [4, 5],\n",
       "        [0, 5],\n",
       "        [5, 0],\n",
       "        [4, 4],\n",
       "        [3, 2],\n",
       "        [0, 1],\n",
       "        [4, 0],\n",
       "        [1, 5],\n",
       "        [5, 5],\n",
       "        [1, 5],\n",
       "        [2, 2],\n",
       "        [4, 4],\n",
       "        [5, 2],\n",
       "        [3, 2],\n",
       "        [2, 0],\n",
       "        [5, 1],\n",
       "        [0, 4],\n",
       "        [2, 4],\n",
       "        [2, 2],\n",
       "        [4, 0],\n",
       "        [0, 4],\n",
       "        [2, 4],\n",
       "        [5, 2],\n",
       "        [1, 4],\n",
       "        [4, 0],\n",
       "        [5, 4],\n",
       "        [4, 0],\n",
       "        [0, 0],\n",
       "        [4, 3],\n",
       "        [5, 0],\n",
       "        [1, 5],\n",
       "        [4, 5],\n",
       "        [0, 4],\n",
       "        [2, 2],\n",
       "        [0, 4],\n",
       "        [1, 5]])>,\n",
       "  'discount': <tf.Tensor: shape=(64, 2), dtype=float32, numpy=\n",
       " array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.]], dtype=float32)>,\n",
       "  'next_step_type': <tf.Tensor: shape=(64, 2), dtype=int32, numpy=\n",
       " array([[1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1]], dtype=int32)>,\n",
       "  'observation': <tf.Tensor: shape=(64, 2), dtype=int64, numpy=\n",
       " array([[311, 211],\n",
       "        [191, 171],\n",
       "        [291, 191],\n",
       "        [331, 331],\n",
       "        [311, 311],\n",
       "        [419, 419],\n",
       "        [311, 311],\n",
       "        [419, 419],\n",
       "        [191, 291],\n",
       "        [271, 251],\n",
       "        [331, 331],\n",
       "        [271, 251],\n",
       "        [171, 191],\n",
       "        [251, 251],\n",
       "        [411, 411],\n",
       "        [191, 191],\n",
       "        [311, 311],\n",
       "        [191, 191],\n",
       "        [419, 411],\n",
       "        [331, 331],\n",
       "        [419, 419],\n",
       "        [251, 231],\n",
       "        [271, 271],\n",
       "        [419, 419],\n",
       "        [271, 271],\n",
       "        [419, 419],\n",
       "        [231, 231],\n",
       "        [251, 231],\n",
       "        [419, 419],\n",
       "        [419, 419],\n",
       "        [311, 311],\n",
       "        [419, 419],\n",
       "        [251, 231],\n",
       "        [311, 411],\n",
       "        [131, 131],\n",
       "        [331, 231],\n",
       "        [251, 251],\n",
       "        [331, 231],\n",
       "        [271, 291],\n",
       "        [419, 419],\n",
       "        [271, 271],\n",
       "        [411, 411],\n",
       "        [319, 319],\n",
       "        [419, 411],\n",
       "        [419, 419],\n",
       "        [231, 251],\n",
       "        [271, 291],\n",
       "        [411, 419],\n",
       "        [419, 419],\n",
       "        [411, 411],\n",
       "        [419, 411],\n",
       "        [411, 311],\n",
       "        [411, 419],\n",
       "        [271, 271],\n",
       "        [131, 131],\n",
       "        [419, 419],\n",
       "        [271, 271],\n",
       "        [411, 411],\n",
       "        [231, 131],\n",
       "        [271, 271],\n",
       "        [171, 271],\n",
       "        [271, 291],\n",
       "        [419, 419],\n",
       "        [419, 319]])>,\n",
       "  'policy_info': (),\n",
       "  'reward': <tf.Tensor: shape=(64, 2), dtype=float32, numpy=\n",
       " array([[ -1.,  -1.],\n",
       "        [ -1., -10.],\n",
       "        [ -1.,  -1.],\n",
       "        [ -1.,  -1.],\n",
       "        [ -1.,  -1.],\n",
       "        [-10., -10.],\n",
       "        [ -1.,  -1.],\n",
       "        [-10.,  -1.],\n",
       "        [ -1.,  -1.],\n",
       "        [ -1.,  -1.],\n",
       "        [ -1.,  -1.],\n",
       "        [ -1.,  -1.],\n",
       "        [ -1.,  -1.],\n",
       "        [-10., -10.],\n",
       "        [ -1.,  -1.],\n",
       "        [ -1.,  -1.],\n",
       "        [-10.,  -1.],\n",
       "        [ -1.,  -1.],\n",
       "        [ -1.,  -1.],\n",
       "        [ -1.,  -1.],\n",
       "        [ -1.,  -1.],\n",
       "        [ -1.,  -1.],\n",
       "        [-10.,  -1.],\n",
       "        [-10.,  -1.],\n",
       "        [-10.,  -1.],\n",
       "        [ -1.,  -1.],\n",
       "        [-10.,  -1.],\n",
       "        [ -1.,  -1.],\n",
       "        [-10.,  -1.],\n",
       "        [ -1.,  -1.],\n",
       "        [-10.,  -1.],\n",
       "        [-10., -10.],\n",
       "        [ -1.,  -1.],\n",
       "        [ -1.,  -1.],\n",
       "        [-10.,  -1.],\n",
       "        [ -1., -10.],\n",
       "        [-10., -10.],\n",
       "        [ -1., -10.],\n",
       "        [ -1.,  -1.],\n",
       "        [-10., -10.],\n",
       "        [-10.,  -1.],\n",
       "        [ -1.,  -1.],\n",
       "        [ -1.,  -1.],\n",
       "        [ -1.,  -1.],\n",
       "        [ -1., -10.],\n",
       "        [ -1., -10.],\n",
       "        [ -1.,  -1.],\n",
       "        [ -1.,  -1.],\n",
       "        [ -1., -10.],\n",
       "        [ -1.,  -1.],\n",
       "        [ -1.,  -1.],\n",
       "        [ -1., -10.],\n",
       "        [ -1.,  -1.],\n",
       "        [-10., -10.],\n",
       "        [-10.,  -1.],\n",
       "        [ -1.,  -1.],\n",
       "        [-10.,  -1.],\n",
       "        [-10.,  -1.],\n",
       "        [ -1., -10.],\n",
       "        [-10., -10.],\n",
       "        [ -1., -10.],\n",
       "        [ -1.,  -1.],\n",
       "        [ -1., -10.],\n",
       "        [ -1., -10.]], dtype=float32)>,\n",
       "  'step_type': <tf.Tensor: shape=(64, 2), dtype=int32, numpy=\n",
       " array([[1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [0, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1]], dtype=int32)>}),\n",
       " BufferInfo(ids=<tf.Tensor: shape=(64, 2), dtype=int64, numpy=\n",
       " array([[54, 55],\n",
       "        [86, 87],\n",
       "        [85, 86],\n",
       "        [59, 60],\n",
       "        [48, 49],\n",
       "        [18, 19],\n",
       "        [46, 47],\n",
       "        [12, 13],\n",
       "        [84, 85],\n",
       "        [97, 98],\n",
       "        [60, 61],\n",
       "        [97, 98],\n",
       "        [83, 84],\n",
       "        [72, 73],\n",
       "        [50, 51],\n",
       "        [81, 82],\n",
       "        [27, 28],\n",
       "        [81, 82],\n",
       "        [ 7,  8],\n",
       "        [59, 60],\n",
       "        [13, 14],\n",
       "        [76, 77],\n",
       "        [96, 97],\n",
       "        [19, 20],\n",
       "        [96, 97],\n",
       "        [13, 14],\n",
       "        [63, 64],\n",
       "        [76, 77],\n",
       "        [ 6,  7],\n",
       "        [20, 21],\n",
       "        [24, 25],\n",
       "        [18, 19],\n",
       "        [98, 99],\n",
       "        [25, 26],\n",
       "        [67, 68],\n",
       "        [61, 62],\n",
       "        [72, 73],\n",
       "        [61, 62],\n",
       "        [91, 92],\n",
       "        [18, 19],\n",
       "        [90, 91],\n",
       "        [50, 51],\n",
       "        [42, 43],\n",
       "        [44, 45],\n",
       "        [16, 17],\n",
       "        [70, 71],\n",
       "        [91, 92],\n",
       "        [ 9, 10],\n",
       "        [16, 17],\n",
       "        [ 0,  1],\n",
       "        [ 7,  8],\n",
       "        [26, 27],\n",
       "        [ 4,  5],\n",
       "        [95, 96],\n",
       "        [67, 68],\n",
       "        [10, 11],\n",
       "        [96, 97],\n",
       "        [33, 34],\n",
       "        [64, 65],\n",
       "        [89, 90],\n",
       "        [88, 89],\n",
       "        [91, 92],\n",
       "        [11, 12],\n",
       "        [40, 41]])>, probabilities=<tf.Tensor: shape=(64,), dtype=float32, numpy=\n",
       " array([0.01010101, 0.01010101, 0.01010101, 0.01010101, 0.01010101,\n",
       "        0.01010101, 0.01010101, 0.01010101, 0.01010101, 0.01010101,\n",
       "        0.01010101, 0.01010101, 0.01010101, 0.01010101, 0.01010101,\n",
       "        0.01010101, 0.01010101, 0.01010101, 0.01010101, 0.01010101,\n",
       "        0.01010101, 0.01010101, 0.01010101, 0.01010101, 0.01010101,\n",
       "        0.01010101, 0.01010101, 0.01010101, 0.01010101, 0.01010101,\n",
       "        0.01010101, 0.01010101, 0.01010101, 0.01010101, 0.01010101,\n",
       "        0.01010101, 0.01010101, 0.01010101, 0.01010101, 0.01010101,\n",
       "        0.01010101, 0.01010101, 0.01010101, 0.01010101, 0.01010101,\n",
       "        0.01010101, 0.01010101, 0.01010101, 0.01010101, 0.01010101,\n",
       "        0.01010101, 0.01010101, 0.01010101, 0.01010101, 0.01010101,\n",
       "        0.01010101, 0.01010101, 0.01010101, 0.01010101, 0.01010101,\n",
       "        0.01010101, 0.01010101, 0.01010101, 0.01010101], dtype=float32)>))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iterator.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.train = common.function(agent.train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'UnreadVariable' shape=() dtype=int32, numpy=0>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.train_step_counter.assign(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_return = compute_avg_return(eval_env, agent.policy, num_eval_episodes)\n",
    "returns = [avg_return]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ajay/.local/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py:1082: calling foldr_v2 (from tensorflow.python.ops.functional_ops) with back_prop=False is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "back_prop=False is deprecated. Consider using tf.stop_gradient instead.\n",
      "Instead of:\n",
      "results = tf.foldr(fn, elems, back_prop=False)\n",
      "Use:\n",
      "results = tf.nest.map_structure(tf.stop_gradient, tf.foldr(fn, elems))\n",
      "step = 200: loss = 961425.1875\n",
      "step = 400: loss = 394212.5625\n",
      "step = 600: loss = 815675.0625\n",
      "step = 800: loss = 2376271.75\n",
      "step = 1000: loss = 19997454.0\n",
      "step = 1000: Average Return = -200.0\n",
      "step = 1200: loss = 3653193.0\n",
      "step = 1400: loss = 1619591.25\n",
      "step = 1600: loss = 1915248.375\n",
      "step = 1800: loss = 2476783.0\n",
      "step = 2000: loss = 3105739.75\n",
      "step = 2000: Average Return = -200.0\n",
      "step = 2200: loss = 86238296.0\n",
      "step = 2400: loss = 10052096.0\n",
      "step = 2600: loss = 164284352.0\n",
      "step = 2800: loss = 16992938.0\n",
      "step = 3000: loss = 16503592.0\n",
      "step = 3000: Average Return = -200.0\n",
      "step = 3200: loss = 2898768.5\n",
      "step = 3400: loss = 37020188.0\n",
      "step = 3600: loss = 14924718.0\n",
      "step = 3800: loss = 35867040.0\n",
      "step = 4000: loss = 26263100.0\n",
      "step = 4000: Average Return = -200.0\n",
      "step = 4200: loss = 329072576.0\n",
      "step = 4400: loss = 438450592.0\n",
      "step = 4600: loss = 1041467.0\n",
      "step = 4800: loss = 632210240.0\n",
      "step = 5000: loss = 35313372.0\n",
      "step = 5000: Average Return = -2000.0\n"
     ]
    }
   ],
   "source": [
    "for _ in range(num_iterations):\n",
    "\n",
    "  # Collect a few steps using collect_policy and save to the replay buffer.\n",
    "  for _ in range(collect_steps_per_iteration):\n",
    "    collect_step(train_env, agent.collect_policy, replay_buffer)\n",
    "\n",
    "  # Sample a batch of data from the buffer and update the agent's network.\n",
    "  experience, unused_info = next(iterator)\n",
    "  train_loss = agent.train(experience)\n",
    "\n",
    "  step = agent.train_step_counter.numpy()\n",
    "\n",
    "  if step % log_interval == 0:\n",
    "    print('step = {0}: loss = {1}'.format(step, train_loss.loss))\n",
    "\n",
    "  if step % eval_interval == 0:\n",
    "    avg_return = compute_avg_return(eval_env, agent.policy, num_eval_episodes)\n",
    "    print('step = {0}: Average Return = {1}'.format(step, avg_return))\n",
    "    returns.append(avg_return)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-2090.0, 250.0)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "iterations = range(0, num_iterations + 1, eval_interval)\n",
    "plt.plot(iterations, returns)\n",
    "plt.ylabel('Average Return')\n",
    "plt.xlabel('Iterations')\n",
    "plt.ylim(top=250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embed_mp4(filename):\n",
    "  \"\"\"Embeds an mp4 file in the notebook.\"\"\"\n",
    "  video = open(filename,'rb').read()\n",
    "  b64 = base64.b64encode(video)\n",
    "  tag = '''\n",
    "  <video width=\"640\" height=\"480\" controls>\n",
    "    <source src=\"data:video/mp4;base64,{0}\" type=\"video/mp4\">\n",
    "  Your browser does not support the video tag.\n",
    "  </video>'''.format(b64.decode())\n",
    "\n",
    "  return IPython.display.HTML(tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imageio\n",
    "\n",
    "def create_policy_eval_video(policy, filename, num_episodes=5, fps=30):\n",
    "  filename = filename + \".mp4\"\n",
    "  with imageio.get_writer(filename, fps=fps) as video:\n",
    "    for _ in range(num_episodes):\n",
    "      time_step = eval_env.reset()\n",
    "      video.append_data(eval_py_env.render())\n",
    "      while not time_step.is_last():\n",
    "        action_step = policy.action(time_step)\n",
    "        time_step = eval_env.step(action_step.action)\n",
    "        video.append_data(eval_py_env.render())\n",
    "  return embed_mp4(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+\n",
      "|\u001b[34;1mR\u001b[0m: | : :\u001b[35mG\u001b[0m|\n",
      "| : |\u001b[43m \u001b[0m: : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|Y| : |B: |\n",
      "+---------+\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/gym/envs/toy_text/taxi.py:253\u001b[0m, in \u001b[0;36mTaxiEnv.render\u001b[0;34m(self, mode)\u001b[0m\n\u001b[1;32m    <a href='file:///home/ajay/.local/lib/python3.8/site-packages/gym/envs/toy_text/taxi.py?line=251'>252</a>\u001b[0m \u001b[39mwith\u001b[39;00m closing(outfile):\n\u001b[0;32m--> <a href='file:///home/ajay/.local/lib/python3.8/site-packages/gym/envs/toy_text/taxi.py?line=252'>253</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m outfile\u001b[39m.\u001b[39;49mgetvalue()\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'OutStream' object has no attribute 'getvalue'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/ajay/code/aisv802_drl_course/taxi_v3/taxi_v3-dqn-tf_agents.ipynb Cell 35'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu/home/ajay/code/aisv802_drl_course/taxi_v3/taxi_v3-dqn-tf_agents.ipynb#ch0000043vscode-remote?line=0'>1</a>\u001b[0m create_policy_eval_video(agent\u001b[39m.\u001b[39;49mpolicy, \u001b[39m\"\u001b[39;49m\u001b[39mtrained-agent\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "\u001b[1;32m/home/ajay/code/aisv802_drl_course/taxi_v3/taxi_v3-dqn-tf_agents.ipynb Cell 34'\u001b[0m in \u001b[0;36mcreate_policy_eval_video\u001b[0;34m(policy, filename, num_episodes, fps)\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/ajay/code/aisv802_drl_course/taxi_v3/taxi_v3-dqn-tf_agents.ipynb#ch0000042vscode-remote?line=5'>6</a>\u001b[0m \u001b[39mfor\u001b[39;00m _ \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(num_episodes):\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/ajay/code/aisv802_drl_course/taxi_v3/taxi_v3-dqn-tf_agents.ipynb#ch0000042vscode-remote?line=6'>7</a>\u001b[0m   time_step \u001b[39m=\u001b[39m eval_env\u001b[39m.\u001b[39mreset()\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu/home/ajay/code/aisv802_drl_course/taxi_v3/taxi_v3-dqn-tf_agents.ipynb#ch0000042vscode-remote?line=7'>8</a>\u001b[0m   video\u001b[39m.\u001b[39mappend_data(eval_py_env\u001b[39m.\u001b[39;49mrender())\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/ajay/code/aisv802_drl_course/taxi_v3/taxi_v3-dqn-tf_agents.ipynb#ch0000042vscode-remote?line=8'>9</a>\u001b[0m   \u001b[39mwhile\u001b[39;00m \u001b[39mnot\u001b[39;00m time_step\u001b[39m.\u001b[39mis_last():\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/ajay/code/aisv802_drl_course/taxi_v3/taxi_v3-dqn-tf_agents.ipynb#ch0000042vscode-remote?line=9'>10</a>\u001b[0m     action_step \u001b[39m=\u001b[39m policy\u001b[39m.\u001b[39maction(time_step)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/tf_agents/environments/wrappers.py:84\u001b[0m, in \u001b[0;36mPyEnvironmentBaseWrapper.render\u001b[0;34m(self, mode)\u001b[0m\n\u001b[1;32m     <a href='file:///home/ajay/.local/lib/python3.8/site-packages/tf_agents/environments/wrappers.py?line=82'>83</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrender\u001b[39m(\u001b[39mself\u001b[39m, mode: Text \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mrgb_array\u001b[39m\u001b[39m'\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m types\u001b[39m.\u001b[39mNestedArray:\n\u001b[0;32m---> <a href='file:///home/ajay/.local/lib/python3.8/site-packages/tf_agents/environments/wrappers.py?line=83'>84</a>\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_env\u001b[39m.\u001b[39;49mrender(mode)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/tf_agents/environments/gym_wrapper.py:264\u001b[0m, in \u001b[0;36mGymWrapper.render\u001b[0;34m(self, mode)\u001b[0m\n\u001b[1;32m    <a href='file:///home/ajay/.local/lib/python3.8/site-packages/tf_agents/environments/gym_wrapper.py?line=262'>263</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrender\u001b[39m(\u001b[39mself\u001b[39m, mode: Text \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mrgb_array\u001b[39m\u001b[39m'\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Any:\n\u001b[0;32m--> <a href='file:///home/ajay/.local/lib/python3.8/site-packages/tf_agents/environments/gym_wrapper.py?line=263'>264</a>\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_gym_env\u001b[39m.\u001b[39;49mrender(mode, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_render_kwargs)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/gym/core.py:286\u001b[0m, in \u001b[0;36mWrapper.render\u001b[0;34m(self, mode, **kwargs)\u001b[0m\n\u001b[1;32m    <a href='file:///home/ajay/.local/lib/python3.8/site-packages/gym/core.py?line=284'>285</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrender\u001b[39m(\u001b[39mself\u001b[39m, mode\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mhuman\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m--> <a href='file:///home/ajay/.local/lib/python3.8/site-packages/gym/core.py?line=285'>286</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49menv\u001b[39m.\u001b[39;49mrender(mode, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/gym/core.py:286\u001b[0m, in \u001b[0;36mWrapper.render\u001b[0;34m(self, mode, **kwargs)\u001b[0m\n\u001b[1;32m    <a href='file:///home/ajay/.local/lib/python3.8/site-packages/gym/core.py?line=284'>285</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrender\u001b[39m(\u001b[39mself\u001b[39m, mode\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mhuman\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m--> <a href='file:///home/ajay/.local/lib/python3.8/site-packages/gym/core.py?line=285'>286</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49menv\u001b[39m.\u001b[39;49mrender(mode, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/gym/envs/toy_text/taxi.py:253\u001b[0m, in \u001b[0;36mTaxiEnv.render\u001b[0;34m(self, mode)\u001b[0m\n\u001b[1;32m    <a href='file:///home/ajay/.local/lib/python3.8/site-packages/gym/envs/toy_text/taxi.py?line=250'>251</a>\u001b[0m \u001b[39mif\u001b[39;00m mode \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mhuman\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    <a href='file:///home/ajay/.local/lib/python3.8/site-packages/gym/envs/toy_text/taxi.py?line=251'>252</a>\u001b[0m     \u001b[39mwith\u001b[39;00m closing(outfile):\n\u001b[0;32m--> <a href='file:///home/ajay/.local/lib/python3.8/site-packages/gym/envs/toy_text/taxi.py?line=252'>253</a>\u001b[0m         \u001b[39mreturn\u001b[39;00m outfile\u001b[39m.\u001b[39mgetvalue()\n",
      "File \u001b[0;32m/usr/lib/python3.8/contextlib.py:299\u001b[0m, in \u001b[0;36mclosing.__exit__\u001b[0;34m(self, *exc_info)\u001b[0m\n\u001b[1;32m    <a href='file:///usr/lib/python3.8/contextlib.py?line=297'>298</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__exit__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39mexc_info):\n\u001b[0;32m--> <a href='file:///usr/lib/python3.8/contextlib.py?line=298'>299</a>\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mthing\u001b[39m.\u001b[39;49mclose()\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/ipykernel/iostream.py:429\u001b[0m, in \u001b[0;36mOutStream.close\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    <a href='file:///usr/local/lib/python3.8/dist-packages/ipykernel/iostream.py?line=426'>427</a>\u001b[0m \u001b[39mif\u001b[39;00m sys\u001b[39m.\u001b[39mplatform\u001b[39m.\u001b[39mstartswith(\u001b[39m\"\u001b[39m\u001b[39mlinux\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mor\u001b[39;00m sys\u001b[39m.\u001b[39mplatform\u001b[39m.\u001b[39mstartswith(\u001b[39m\"\u001b[39m\u001b[39mdarwin\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m    <a href='file:///usr/local/lib/python3.8/dist-packages/ipykernel/iostream.py?line=427'>428</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_should_watch \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m--> <a href='file:///usr/local/lib/python3.8/dist-packages/ipykernel/iostream.py?line=428'>429</a>\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mwatch_fd_thread\u001b[39m.\u001b[39;49mjoin()\n\u001b[1;32m    <a href='file:///usr/local/lib/python3.8/dist-packages/ipykernel/iostream.py?line=429'>430</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exc:\n\u001b[1;32m    <a href='file:///usr/local/lib/python3.8/dist-packages/ipykernel/iostream.py?line=430'>431</a>\u001b[0m     etype, value, tb \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exc\n",
      "File \u001b[0;32m/usr/lib/python3.8/threading.py:1011\u001b[0m, in \u001b[0;36mThread.join\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   <a href='file:///usr/lib/python3.8/threading.py?line=1007'>1008</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mcannot join current thread\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   <a href='file:///usr/lib/python3.8/threading.py?line=1009'>1010</a>\u001b[0m \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> <a href='file:///usr/lib/python3.8/threading.py?line=1010'>1011</a>\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_wait_for_tstate_lock()\n\u001b[1;32m   <a href='file:///usr/lib/python3.8/threading.py?line=1011'>1012</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   <a href='file:///usr/lib/python3.8/threading.py?line=1012'>1013</a>\u001b[0m     \u001b[39m# the behavior of a negative timeout isn't documented, but\u001b[39;00m\n\u001b[1;32m   <a href='file:///usr/lib/python3.8/threading.py?line=1013'>1014</a>\u001b[0m     \u001b[39m# historically .join(timeout=x) for x<0 has acted as if timeout=0\u001b[39;00m\n\u001b[1;32m   <a href='file:///usr/lib/python3.8/threading.py?line=1014'>1015</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_wait_for_tstate_lock(timeout\u001b[39m=\u001b[39m\u001b[39mmax\u001b[39m(timeout, \u001b[39m0\u001b[39m))\n",
      "File \u001b[0;32m/usr/lib/python3.8/threading.py:1027\u001b[0m, in \u001b[0;36mThread._wait_for_tstate_lock\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m   <a href='file:///usr/lib/python3.8/threading.py?line=1024'>1025</a>\u001b[0m \u001b[39mif\u001b[39;00m lock \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:  \u001b[39m# already determined that the C code is done\u001b[39;00m\n\u001b[1;32m   <a href='file:///usr/lib/python3.8/threading.py?line=1025'>1026</a>\u001b[0m     \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_is_stopped\n\u001b[0;32m-> <a href='file:///usr/lib/python3.8/threading.py?line=1026'>1027</a>\u001b[0m \u001b[39melif\u001b[39;00m lock\u001b[39m.\u001b[39;49macquire(block, timeout):\n\u001b[1;32m   <a href='file:///usr/lib/python3.8/threading.py?line=1027'>1028</a>\u001b[0m     lock\u001b[39m.\u001b[39mrelease()\n\u001b[1;32m   <a href='file:///usr/lib/python3.8/threading.py?line=1028'>1029</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stop()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "create_policy_eval_video(agent.policy, \"trained-agent\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
