{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-27 11:43:38.529855: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-03-27 11:43:38.529906: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import, division, print_function\n",
    "\n",
    "import IPython\n",
    "import numpy as np\n",
    "import base64\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from tf_agents.agents.dqn import dqn_agent\n",
    "from tf_agents.environments import suite_gym\n",
    "from tf_agents.environments import tf_py_environment\n",
    "from tf_agents.networks import q_network\n",
    "from tf_agents.policies import random_tf_policy\n",
    "from tf_agents.replay_buffers import tf_uniform_replay_buffer\n",
    "from tf_agents.trajectories import trajectory\n",
    "from tf_agents.utils import common"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_iterations = 5000 # @param {type:\"integer\"}\n",
    "\n",
    "initial_collect_steps = 100  # @param {type:\"integer\"}\n",
    "collect_steps_per_iteration =   1# @param {type:\"integer\"}\n",
    "replay_buffer_max_length = 1000  # @param {type:\"integer\"}\n",
    "\n",
    "batch_size = 64  # @param {type:\"integer\"}\n",
    "learning_rate = 1e-3  # @param {type:\"number\"}\n",
    "log_interval = 200  # @param {type:\"integer\"}\n",
    "\n",
    "num_eval_episodes = 10  # @param {type:\"integer\"}\n",
    "eval_interval = 1000  # @param {type:\"integer\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TimeStep(\n",
       "{'discount': array(1., dtype=float32),\n",
       " 'observation': array(162),\n",
       " 'reward': array(0., dtype=float32),\n",
       " 'step_type': array(0, dtype=int32)})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env_name = 'Taxi-v3'\n",
    "env = suite_gym.load(env_name)\n",
    "env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#env.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observation Spec:\n",
      "BoundedArraySpec(shape=(), dtype=dtype('int64'), name='observation', minimum=0, maximum=499)\n"
     ]
    }
   ],
   "source": [
    "print('Observation Spec:')\n",
    "print(env.time_step_spec().observation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reward Spec:\n",
      "ArraySpec(shape=(), dtype=dtype('float32'), name='reward')\n"
     ]
    }
   ],
   "source": [
    "print('Reward Spec:')\n",
    "print(env.time_step_spec().reward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action Spec:\n",
      "BoundedArraySpec(shape=(), dtype=dtype('int64'), name='action', minimum=0, maximum=5)\n"
     ]
    }
   ],
   "source": [
    "print('Action Spec:')\n",
    "print(env.action_spec())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time step:\n",
      "TimeStep(\n",
      "{'discount': array(1., dtype=float32),\n",
      " 'observation': array(169),\n",
      " 'reward': array(0., dtype=float32),\n",
      " 'step_type': array(0, dtype=int32)})\n",
      "Next time step:\n",
      "TimeStep(\n",
      "{'discount': array(1., dtype=float32),\n",
      " 'observation': array(69),\n",
      " 'reward': array(-1., dtype=float32),\n",
      " 'step_type': array(1, dtype=int32)})\n"
     ]
    }
   ],
   "source": [
    "time_step = env.reset()\n",
    "print('Time step:')\n",
    "print(time_step)\n",
    "\n",
    "action = np.array(1, dtype=np.int32)\n",
    "\n",
    "next_time_step = env.step(action)\n",
    "print('Next time step:')\n",
    "print(next_time_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_py_env = suite_gym.load(env_name)\n",
    "eval_py_env = suite_gym.load(env_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_env = tf_py_environment.TFPyEnvironment(train_py_env)\n",
    "eval_env = tf_py_environment.TFPyEnvironment(eval_py_env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fc_layer_params = (10, 10, 50, 50, )\n",
    "fc_layer_params = (100, )\n",
    "q_net = q_network.QNetwork(\n",
    "    train_env.observation_spec(),\n",
    "    train_env.action_spec(),\n",
    "    fc_layer_params=fc_layer_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-27 11:43:55.610390: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:922] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-03-27 11:43:55.610591: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-03-27 11:43:55.610638: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory\n",
      "2022-03-27 11:43:55.610714: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory\n",
      "2022-03-27 11:43:55.610788: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcufft.so.10'; dlerror: libcufft.so.10: cannot open shared object file: No such file or directory\n",
      "2022-03-27 11:43:55.610828: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcurand.so.10'; dlerror: libcurand.so.10: cannot open shared object file: No such file or directory\n",
      "2022-03-27 11:43:55.610863: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory\n",
      "2022-03-27 11:43:55.610895: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory\n",
      "2022-03-27 11:43:55.610961: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2022-03-27 11:43:55.610971: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1850] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2022-03-27 11:43:55.611550: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "\n",
    "train_step_counter = tf.Variable(0)\n",
    "\n",
    "agent = dqn_agent.DqnAgent(\n",
    "    train_env.time_step_spec(),\n",
    "    train_env.action_spec(),\n",
    "    q_network=q_net,\n",
    "    optimizer=optimizer,\n",
    "    td_errors_loss_fn=common.element_wise_squared_loss,\n",
    "    train_step_counter=train_step_counter)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_policy = agent.policy\n",
    "collect_policy = agent.collect_policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_policy = random_tf_policy.RandomTFPolicy(train_env.time_step_spec(),\n",
    "                                                train_env.action_spec())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_avg_return(environment, policy, num_episodes=10):\n",
    "\n",
    "  total_return = 0.0\n",
    "  for _ in range(num_episodes):\n",
    "\n",
    "    time_step = environment.reset()\n",
    "    episode_return = 0.0\n",
    "\n",
    "    while not time_step.is_last():\n",
    "      action_step = policy.action(time_step)\n",
    "      time_step = environment.step(action_step.action)\n",
    "      episode_return += time_step.reward\n",
    "    total_return += episode_return\n",
    "\n",
    "  avg_return = total_return / num_episodes\n",
    "  return avg_return.numpy()[0]\n",
    "\n",
    "\n",
    "# See also the metrics module for standard implementations of different metrics.\n",
    "# https://github.com/tensorflow/agents/tree/master/tf_agents/metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-774.1"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_avg_return(eval_env, random_policy, num_eval_episodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "replay_buffer = tf_uniform_replay_buffer.TFUniformReplayBuffer(\n",
    "    data_spec=agent.collect_data_spec,\n",
    "    batch_size=train_env.batch_size,\n",
    "    max_length=replay_buffer_max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trajectory(\n",
      "{'action': BoundedTensorSpec(shape=(), dtype=tf.int64, name='action', minimum=array(0), maximum=array(5)),\n",
      " 'discount': BoundedTensorSpec(shape=(), dtype=tf.float32, name='discount', minimum=array(0., dtype=float32), maximum=array(1., dtype=float32)),\n",
      " 'next_step_type': TensorSpec(shape=(), dtype=tf.int32, name='step_type'),\n",
      " 'observation': BoundedTensorSpec(shape=(), dtype=tf.int64, name='observation', minimum=array(0), maximum=array(499)),\n",
      " 'policy_info': (),\n",
      " 'reward': TensorSpec(shape=(), dtype=tf.float32, name='reward'),\n",
      " 'step_type': TensorSpec(shape=(), dtype=tf.int32, name='step_type')})\n",
      "('step_type', 'observation', 'action', 'policy_info', 'next_step_type', 'reward', 'discount')\n"
     ]
    }
   ],
   "source": [
    "print(agent.collect_data_spec)\n",
    "print(agent.collect_data_spec._fields)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_step(environment, policy, buffer):\n",
    "  time_step = environment.current_time_step()\n",
    "  action_step = policy.action(time_step)\n",
    "  # Do not use the below. It use tensor objects which cause error\n",
    "  # next_time_step = environment.step(action_step.action)\n",
    "  # For step argument, we put numpy object as action integer like below\n",
    "  next_time_step = environment.step(action_step.action.numpy()[0])\n",
    "  traj = trajectory.from_transition(time_step, action_step, next_time_step)\n",
    "\n",
    "  # Add trajectory to the replay buffer\n",
    "  buffer.add_batch(traj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_data(env, policy, buffer, steps):\n",
    "  for _ in range(steps):\n",
    "    collect_step(env, policy, buffer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "collect_data(train_env, random_policy, replay_buffer, steps=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf_agents.replay_buffers.tf_uniform_replay_buffer.TFUniformReplayBuffer at 0x7fb42c05c6d0>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "replay_buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ajay/.local/lib/python3.8/site-packages/tensorflow/python/autograph/impl/api.py:377: ReplayBuffer.get_next (from tf_agents.replay_buffers.replay_buffer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `as_dataset(..., single_deterministic_pass=False) instead.\n"
     ]
    }
   ],
   "source": [
    "dataset = replay_buffer.as_dataset(\n",
    "    num_parallel_calls=3,\n",
    "    sample_batch_size=batch_size,\n",
    "    num_steps=2).prefetch(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<PrefetchDataset element_spec=(Trajectory(\n",
       "{'action': TensorSpec(shape=(64, 2), dtype=tf.int64, name=None),\n",
       " 'discount': TensorSpec(shape=(64, 2), dtype=tf.float32, name=None),\n",
       " 'next_step_type': TensorSpec(shape=(64, 2), dtype=tf.int32, name=None),\n",
       " 'observation': TensorSpec(shape=(64, 2), dtype=tf.int64, name=None),\n",
       " 'policy_info': (),\n",
       " 'reward': TensorSpec(shape=(64, 2), dtype=tf.float32, name=None),\n",
       " 'step_type': TensorSpec(shape=(64, 2), dtype=tf.int32, name=None)}), BufferInfo(ids=TensorSpec(shape=(64, 2), dtype=tf.int64, name=None), probabilities=TensorSpec(shape=(64,), dtype=tf.float32, name=None)))>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tensorflow.python.data.ops.iterator_ops.OwnedIterator object at 0x7fb4245c5a00>\n"
     ]
    }
   ],
   "source": [
    "iterator = iter(dataset)\n",
    "print(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Trajectory(\n",
       " {'action': <tf.Tensor: shape=(64, 2), dtype=int64, numpy=\n",
       " array([[1, 3],\n",
       "        [3, 5],\n",
       "        [1, 3],\n",
       "        [3, 3],\n",
       "        [2, 0],\n",
       "        [4, 4],\n",
       "        [3, 3],\n",
       "        [4, 0],\n",
       "        [0, 1],\n",
       "        [3, 3],\n",
       "        [3, 1],\n",
       "        [3, 3],\n",
       "        [2, 0],\n",
       "        [5, 5],\n",
       "        [3, 2],\n",
       "        [2, 3],\n",
       "        [4, 2],\n",
       "        [2, 3],\n",
       "        [5, 2],\n",
       "        [3, 3],\n",
       "        [0, 2],\n",
       "        [3, 2],\n",
       "        [4, 3],\n",
       "        [4, 0],\n",
       "        [4, 3],\n",
       "        [0, 2],\n",
       "        [5, 1],\n",
       "        [3, 2],\n",
       "        [4, 5],\n",
       "        [0, 5],\n",
       "        [5, 0],\n",
       "        [4, 4],\n",
       "        [3, 2],\n",
       "        [0, 1],\n",
       "        [4, 0],\n",
       "        [1, 5],\n",
       "        [5, 5],\n",
       "        [1, 5],\n",
       "        [2, 2],\n",
       "        [4, 4],\n",
       "        [5, 2],\n",
       "        [3, 2],\n",
       "        [2, 0],\n",
       "        [5, 1],\n",
       "        [0, 4],\n",
       "        [2, 4],\n",
       "        [2, 2],\n",
       "        [4, 0],\n",
       "        [0, 4],\n",
       "        [2, 4],\n",
       "        [5, 2],\n",
       "        [1, 4],\n",
       "        [4, 0],\n",
       "        [5, 4],\n",
       "        [4, 0],\n",
       "        [0, 0],\n",
       "        [4, 3],\n",
       "        [5, 0],\n",
       "        [1, 5],\n",
       "        [4, 5],\n",
       "        [0, 4],\n",
       "        [2, 2],\n",
       "        [0, 4],\n",
       "        [1, 5]])>,\n",
       "  'discount': <tf.Tensor: shape=(64, 2), dtype=float32, numpy=\n",
       " array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.]], dtype=float32)>,\n",
       "  'next_step_type': <tf.Tensor: shape=(64, 2), dtype=int32, numpy=\n",
       " array([[1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1]], dtype=int32)>,\n",
       "  'observation': <tf.Tensor: shape=(64, 2), dtype=int64, numpy=\n",
       " array([[311, 211],\n",
       "        [191, 171],\n",
       "        [291, 191],\n",
       "        [331, 331],\n",
       "        [311, 311],\n",
       "        [419, 419],\n",
       "        [311, 311],\n",
       "        [419, 419],\n",
       "        [191, 291],\n",
       "        [271, 251],\n",
       "        [331, 331],\n",
       "        [271, 251],\n",
       "        [171, 191],\n",
       "        [251, 251],\n",
       "        [411, 411],\n",
       "        [191, 191],\n",
       "        [311, 311],\n",
       "        [191, 191],\n",
       "        [419, 411],\n",
       "        [331, 331],\n",
       "        [419, 419],\n",
       "        [251, 231],\n",
       "        [271, 271],\n",
       "        [419, 419],\n",
       "        [271, 271],\n",
       "        [419, 419],\n",
       "        [231, 231],\n",
       "        [251, 231],\n",
       "        [419, 419],\n",
       "        [419, 419],\n",
       "        [311, 311],\n",
       "        [419, 419],\n",
       "        [251, 231],\n",
       "        [311, 411],\n",
       "        [131, 131],\n",
       "        [331, 231],\n",
       "        [251, 251],\n",
       "        [331, 231],\n",
       "        [271, 291],\n",
       "        [419, 419],\n",
       "        [271, 271],\n",
       "        [411, 411],\n",
       "        [319, 319],\n",
       "        [419, 411],\n",
       "        [419, 419],\n",
       "        [231, 251],\n",
       "        [271, 291],\n",
       "        [411, 419],\n",
       "        [419, 419],\n",
       "        [411, 411],\n",
       "        [419, 411],\n",
       "        [411, 311],\n",
       "        [411, 419],\n",
       "        [271, 271],\n",
       "        [131, 131],\n",
       "        [419, 419],\n",
       "        [271, 271],\n",
       "        [411, 411],\n",
       "        [231, 131],\n",
       "        [271, 271],\n",
       "        [171, 271],\n",
       "        [271, 291],\n",
       "        [419, 419],\n",
       "        [419, 319]])>,\n",
       "  'policy_info': (),\n",
       "  'reward': <tf.Tensor: shape=(64, 2), dtype=float32, numpy=\n",
       " array([[ -1.,  -1.],\n",
       "        [ -1., -10.],\n",
       "        [ -1.,  -1.],\n",
       "        [ -1.,  -1.],\n",
       "        [ -1.,  -1.],\n",
       "        [-10., -10.],\n",
       "        [ -1.,  -1.],\n",
       "        [-10.,  -1.],\n",
       "        [ -1.,  -1.],\n",
       "        [ -1.,  -1.],\n",
       "        [ -1.,  -1.],\n",
       "        [ -1.,  -1.],\n",
       "        [ -1.,  -1.],\n",
       "        [-10., -10.],\n",
       "        [ -1.,  -1.],\n",
       "        [ -1.,  -1.],\n",
       "        [-10.,  -1.],\n",
       "        [ -1.,  -1.],\n",
       "        [ -1.,  -1.],\n",
       "        [ -1.,  -1.],\n",
       "        [ -1.,  -1.],\n",
       "        [ -1.,  -1.],\n",
       "        [-10.,  -1.],\n",
       "        [-10.,  -1.],\n",
       "        [-10.,  -1.],\n",
       "        [ -1.,  -1.],\n",
       "        [-10.,  -1.],\n",
       "        [ -1.,  -1.],\n",
       "        [-10.,  -1.],\n",
       "        [ -1.,  -1.],\n",
       "        [-10.,  -1.],\n",
       "        [-10., -10.],\n",
       "        [ -1.,  -1.],\n",
       "        [ -1.,  -1.],\n",
       "        [-10.,  -1.],\n",
       "        [ -1., -10.],\n",
       "        [-10., -10.],\n",
       "        [ -1., -10.],\n",
       "        [ -1.,  -1.],\n",
       "        [-10., -10.],\n",
       "        [-10.,  -1.],\n",
       "        [ -1.,  -1.],\n",
       "        [ -1.,  -1.],\n",
       "        [ -1.,  -1.],\n",
       "        [ -1., -10.],\n",
       "        [ -1., -10.],\n",
       "        [ -1.,  -1.],\n",
       "        [ -1.,  -1.],\n",
       "        [ -1., -10.],\n",
       "        [ -1.,  -1.],\n",
       "        [ -1.,  -1.],\n",
       "        [ -1., -10.],\n",
       "        [ -1.,  -1.],\n",
       "        [-10., -10.],\n",
       "        [-10.,  -1.],\n",
       "        [ -1.,  -1.],\n",
       "        [-10.,  -1.],\n",
       "        [-10.,  -1.],\n",
       "        [ -1., -10.],\n",
       "        [-10., -10.],\n",
       "        [ -1., -10.],\n",
       "        [ -1.,  -1.],\n",
       "        [ -1., -10.],\n",
       "        [ -1., -10.]], dtype=float32)>,\n",
       "  'step_type': <tf.Tensor: shape=(64, 2), dtype=int32, numpy=\n",
       " array([[1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [0, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1]], dtype=int32)>}),\n",
       " BufferInfo(ids=<tf.Tensor: shape=(64, 2), dtype=int64, numpy=\n",
       " array([[54, 55],\n",
       "        [86, 87],\n",
       "        [85, 86],\n",
       "        [59, 60],\n",
       "        [48, 49],\n",
       "        [18, 19],\n",
       "        [46, 47],\n",
       "        [12, 13],\n",
       "        [84, 85],\n",
       "        [97, 98],\n",
       "        [60, 61],\n",
       "        [97, 98],\n",
       "        [83, 84],\n",
       "        [72, 73],\n",
       "        [50, 51],\n",
       "        [81, 82],\n",
       "        [27, 28],\n",
       "        [81, 82],\n",
       "        [ 7,  8],\n",
       "        [59, 60],\n",
       "        [13, 14],\n",
       "        [76, 77],\n",
       "        [96, 97],\n",
       "        [19, 20],\n",
       "        [96, 97],\n",
       "        [13, 14],\n",
       "        [63, 64],\n",
       "        [76, 77],\n",
       "        [ 6,  7],\n",
       "        [20, 21],\n",
       "        [24, 25],\n",
       "        [18, 19],\n",
       "        [98, 99],\n",
       "        [25, 26],\n",
       "        [67, 68],\n",
       "        [61, 62],\n",
       "        [72, 73],\n",
       "        [61, 62],\n",
       "        [91, 92],\n",
       "        [18, 19],\n",
       "        [90, 91],\n",
       "        [50, 51],\n",
       "        [42, 43],\n",
       "        [44, 45],\n",
       "        [16, 17],\n",
       "        [70, 71],\n",
       "        [91, 92],\n",
       "        [ 9, 10],\n",
       "        [16, 17],\n",
       "        [ 0,  1],\n",
       "        [ 7,  8],\n",
       "        [26, 27],\n",
       "        [ 4,  5],\n",
       "        [95, 96],\n",
       "        [67, 68],\n",
       "        [10, 11],\n",
       "        [96, 97],\n",
       "        [33, 34],\n",
       "        [64, 65],\n",
       "        [89, 90],\n",
       "        [88, 89],\n",
       "        [91, 92],\n",
       "        [11, 12],\n",
       "        [40, 41]])>, probabilities=<tf.Tensor: shape=(64,), dtype=float32, numpy=\n",
       " array([0.01010101, 0.01010101, 0.01010101, 0.01010101, 0.01010101,\n",
       "        0.01010101, 0.01010101, 0.01010101, 0.01010101, 0.01010101,\n",
       "        0.01010101, 0.01010101, 0.01010101, 0.01010101, 0.01010101,\n",
       "        0.01010101, 0.01010101, 0.01010101, 0.01010101, 0.01010101,\n",
       "        0.01010101, 0.01010101, 0.01010101, 0.01010101, 0.01010101,\n",
       "        0.01010101, 0.01010101, 0.01010101, 0.01010101, 0.01010101,\n",
       "        0.01010101, 0.01010101, 0.01010101, 0.01010101, 0.01010101,\n",
       "        0.01010101, 0.01010101, 0.01010101, 0.01010101, 0.01010101,\n",
       "        0.01010101, 0.01010101, 0.01010101, 0.01010101, 0.01010101,\n",
       "        0.01010101, 0.01010101, 0.01010101, 0.01010101, 0.01010101,\n",
       "        0.01010101, 0.01010101, 0.01010101, 0.01010101, 0.01010101,\n",
       "        0.01010101, 0.01010101, 0.01010101, 0.01010101, 0.01010101,\n",
       "        0.01010101, 0.01010101, 0.01010101, 0.01010101], dtype=float32)>))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iterator.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.train = common.function(agent.train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'UnreadVariable' shape=() dtype=int32, numpy=0>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.train_step_counter.assign(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_return = compute_avg_return(eval_env, agent.policy, num_eval_episodes)\n",
    "returns = [avg_return]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ajay/.local/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py:1082: calling foldr_v2 (from tensorflow.python.ops.functional_ops) with back_prop=False is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "back_prop=False is deprecated. Consider using tf.stop_gradient instead.\n",
      "Instead of:\n",
      "results = tf.foldr(fn, elems, back_prop=False)\n",
      "Use:\n",
      "results = tf.nest.map_structure(tf.stop_gradient, tf.foldr(fn, elems))\n",
      "step = 200: loss = 961425.1875\n",
      "step = 400: loss = 394212.5625\n",
      "step = 600: loss = 815675.0625\n",
      "step = 800: loss = 2376271.75\n",
      "step = 1000: loss = 19997454.0\n",
      "step = 1000: Average Return = -200.0\n",
      "step = 1200: loss = 3653193.0\n",
      "step = 1400: loss = 1619591.25\n",
      "step = 1600: loss = 1915248.375\n",
      "step = 1800: loss = 2476783.0\n",
      "step = 2000: loss = 3105739.75\n",
      "step = 2000: Average Return = -200.0\n",
      "step = 2200: loss = 86238296.0\n",
      "step = 2400: loss = 10052096.0\n",
      "step = 2600: loss = 164284352.0\n",
      "step = 2800: loss = 16992938.0\n",
      "step = 3000: loss = 16503592.0\n",
      "step = 3000: Average Return = -200.0\n",
      "step = 3200: loss = 2898768.5\n",
      "step = 3400: loss = 37020188.0\n",
      "step = 3600: loss = 14924718.0\n",
      "step = 3800: loss = 35867040.0\n",
      "step = 4000: loss = 26263100.0\n",
      "step = 4000: Average Return = -200.0\n",
      "step = 4200: loss = 329072576.0\n",
      "step = 4400: loss = 438450592.0\n",
      "step = 4600: loss = 1041467.0\n",
      "step = 4800: loss = 632210240.0\n",
      "step = 5000: loss = 35313372.0\n",
      "step = 5000: Average Return = -2000.0\n"
     ]
    }
   ],
   "source": [
    "for _ in range(num_iterations):\n",
    "\n",
    "  # Collect a few steps using collect_policy and save to the replay buffer.\n",
    "  for _ in range(collect_steps_per_iteration):\n",
    "    collect_step(train_env, agent.collect_policy, replay_buffer)\n",
    "\n",
    "  # Sample a batch of data from the buffer and update the agent's network.\n",
    "  experience, unused_info = next(iterator)\n",
    "  train_loss = agent.train(experience)\n",
    "\n",
    "  step = agent.train_step_counter.numpy()\n",
    "\n",
    "  if step % log_interval == 0:\n",
    "    print('step = {0}: loss = {1}'.format(step, train_loss.loss))\n",
    "\n",
    "  if step % eval_interval == 0:\n",
    "    avg_return = compute_avg_return(eval_env, agent.policy, num_eval_episodes)\n",
    "    print('step = {0}: Average Return = {1}'.format(step, avg_return))\n",
    "    returns.append(avg_return)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterations = range(0, num_iterations + 1, eval_interval)\n",
    "plt.plot(iterations, returns)\n",
    "plt.ylabel('Average Return')\n",
    "plt.xlabel('Iterations')\n",
    "plt.ylim(top=250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embed_mp4(filename):\n",
    "  \"\"\"Embeds an mp4 file in the notebook.\"\"\"\n",
    "  video = open(filename,'rb').read()\n",
    "  b64 = base64.b64encode(video)\n",
    "  tag = '''\n",
    "  <video width=\"640\" height=\"480\" controls>\n",
    "    <source src=\"data:video/mp4;base64,{0}\" type=\"video/mp4\">\n",
    "  Your browser does not support the video tag.\n",
    "  </video>'''.format(b64.decode())\n",
    "\n",
    "  return IPython.display.HTML(tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imageio\n",
    "num_episodes = 3\n",
    "video_filename = 'imageio.mp4'\n",
    "with imageio.get_writer(video_filename, fps=60) as video:\n",
    "  for _ in range(num_episodes):\n",
    "    time_step = eval_py_env.reset()\n",
    "    video.append_data(eval_py_env.render())\n",
    "    while not time_step.is_last():\n",
    "      action_step = agent.policy.action(time_step)\n",
    "      time_step = eval_env.step(action_step.action)\n",
    "      video.append_data(eval_py_env.render())\n",
    "\n",
    "# embed_mp4(video_filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
